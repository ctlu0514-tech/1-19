import pandas as pd
import os
import sys

# --- 1. é…ç½®åŒºåŸŸ ---
FEATURES_FILE_PATH = r'/data/qh_20T_share_file/lct/CT67/dl_work/new_code/features_output/all_features.csv'
LABEL_FILE_PATH = r'/data/qh_20T_share_file/lct/CT67/qianliexian_clinical_isup.csv'
FEATURES_ID_COLUMN_NAME = 'patient_id'
LABEL_ID_COLUMN_NAME = 'id'
LABEL_COLUMN_NAME = 'isup2'
OUTPUT_FILE_PATH = r'/data/qh_20T_share_file/lct/CT67/dl_work/new_code/features_output/all_features_with_label.csv'
CENTER_VALUE = None 

# --- 2. ä¸»ç¨‹åº ---
print("--- è„šæœ¬å¼€å§‹ ---")

# --- åŠ è½½æ•°æ®å¹¶ç«‹å³æ£€æŸ¥ ---
try:
    print(f"æ­£åœ¨åŠ è½½ç‰¹å¾æ–‡ä»¶: {FEATURES_FILE_PATH}")
    # low_memory=False é˜²æ­¢å¤§æ–‡ä»¶åˆ—æ··åˆè­¦å‘Š
    df_features = pd.read_csv(FEATURES_FILE_PATH, low_memory=False) 
    
    # ã€ä¾¦æ¢ç‚¹ 1ã€‘: åˆšè¯»è¿›æ¥æ˜¯å¤šå°‘åˆ—ï¼Ÿ
    print(f"âœ… [æ£€æŸ¥ç‚¹1] ç‰¹å¾æ–‡ä»¶åŸå§‹å¤§å°: {df_features.shape} (è¡Œ, åˆ—)")
    original_feature_cols = set(df_features.columns) # è®°å½•åŸå§‹æ‰€æœ‰åˆ—å
    
except FileNotFoundError:
    print(f"!!! è‡´å‘½é”™è¯¯: æ‰¾ä¸åˆ°ç‰¹å¾æ–‡ä»¶ã€‚")
    sys.exit(1)

try:
    print(f"æ­£åœ¨åŠ è½½æ ‡ç­¾æ–‡ä»¶: {LABEL_FILE_PATH}")
    df_labels = pd.read_csv(LABEL_FILE_PATH)
except FileNotFoundError:
    print(f"!!! è‡´å‘½é”™è¯¯: æ‰¾ä¸åˆ°æ ‡ç­¾æ–‡ä»¶ã€‚")
    sys.exit(1)

# --- å‡†å¤‡å·¥ä½œ ---
if FEATURES_ID_COLUMN_NAME not in df_features.columns:
    print(f"!!! è‡´å‘½é”™è¯¯: ç‰¹å¾æ–‡ä»¶ä¸­æ‰¾ä¸åˆ°IDåˆ— '{FEATURES_ID_COLUMN_NAME}'")
    sys.exit(1)
    
# ç»Ÿä¸€IDç±»å‹
df_features[FEATURES_ID_COLUMN_NAME] = df_features[FEATURES_ID_COLUMN_NAME].astype(str)

# å‡†å¤‡æ ‡ç­¾æ•°æ®
if LABEL_ID_COLUMN_NAME not in df_labels.columns or LABEL_COLUMN_NAME not in df_labels.columns:
    print(f"!!! é”™è¯¯: æ ‡ç­¾æ–‡ä»¶åˆ—åä¸å¯¹ã€‚")
    sys.exit(1)

df_labels_subset = df_labels[[LABEL_ID_COLUMN_NAME, LABEL_COLUMN_NAME]].copy()
df_labels_subset[LABEL_ID_COLUMN_NAME] = df_labels_subset[LABEL_ID_COLUMN_NAME].astype(str)

# --- åˆå¹¶ ---
print("\n--- æ­£åœ¨åˆå¹¶ ---")
df_merged = pd.merge(
    df_features,
    df_labels_subset,
    left_on=FEATURES_ID_COLUMN_NAME,
    right_on=LABEL_ID_COLUMN_NAME,
    how='left'
)
print(f"âœ… [æ£€æŸ¥ç‚¹2] åˆå¹¶åå¤§å°: {df_merged.shape}")

# --- æ¸…ç†ä¸é‡æ’ ---

# 1. æ£€æŸ¥æœªåŒ¹é…ID
missing_count = df_merged[LABEL_COLUMN_NAME].isna().sum()
if missing_count > 0:
    print(f"!!! è­¦å‘Š: {missing_count} è¡ŒæœªåŒ¹é…åˆ°æ ‡ç­¾ã€‚")

# 2. åˆ é™¤å¤šä½™IDåˆ—
# æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬è®°å½•ä¸€ä¸‹ï¼Œæˆ‘ä»¬è¦åˆ çš„æ˜¯ LABEL_ID_COLUMN_NAME
# å¦‚æœ LABEL_ID_COLUMN_NAME å’Œ FEATURES_ID_COLUMN_NAME åå­—ä¸€æ ·ï¼Œè¿™é‡Œå¤„ç†ä¼šæœ‰æ‰€ä¸åŒ
# ä½†é€šå¸¸å®ƒæ˜¯ 'id' å’Œ 'PatientID'ï¼Œæ‰€ä»¥æ²¡é—®é¢˜
if LABEL_ID_COLUMN_NAME in df_merged.columns and LABEL_ID_COLUMN_NAME != FEATURES_ID_COLUMN_NAME:
    df_merged = df_merged.drop([LABEL_ID_COLUMN_NAME], axis=1)

# 3. å¤„ç† Center
center_col_name = 'Center'
use_center = False
if 'CENTER_VALUE' in locals() and CENTER_VALUE is not None:
    use_center = True
    df_merged[center_col_name] = CENTER_VALUE

# 4. é‡æ’é¡ºåº
all_cols = df_merged.columns.tolist()
# æ’é™¤æ‰ ID, Label, Centerï¼Œå‰©ä¸‹çš„å…¨å½“ç‰¹å¾
feature_cols = [c for c in all_cols if c not in [FEATURES_ID_COLUMN_NAME, LABEL_COLUMN_NAME, center_col_name]]

final_order = []
final_order.append(FEATURES_ID_COLUMN_NAME)
if use_center:
    final_order.append(center_col_name)
final_order.append(LABEL_COLUMN_NAME)
final_order.extend(feature_cols)

df_final = df_merged[final_order]

print(f"âœ… [æ£€æŸ¥ç‚¹3] æœ€ç»ˆå¤„ç†åå¤§å°: {df_final.shape}")

# =======================================================
# ã€æ ¸å¿ƒä¿®æ”¹ã€‘: æ¶ˆå¤±çš„ç‰¹å¾å»å“ªäº†ï¼Ÿå¯¹æ¯”åˆ†æ
# =======================================================
print("\n" + "="*40)
print("ğŸ” ä¸¢å¤±åˆ—ä¾¦æ¢æŠ¥å‘Š")
print("="*40)

final_cols_set = set(df_final.columns)
# è®¡ç®—å·®é›†ï¼šåŸå§‹æœ‰ä½†ç°åœ¨æ²¡æœ‰çš„åˆ—
dropped_cols = original_feature_cols - final_cols_set

# æ³¨æ„ï¼šè¿˜è¦æ’é™¤æ‰æ ‡ç­¾æ–‡ä»¶é‚£ä¸ªå¤šä½™çš„IDåˆ—ï¼Œé‚£ä¸ªæ˜¯æˆ‘ä»¬æ•…æ„åˆ çš„
if LABEL_ID_COLUMN_NAME in dropped_cols:
    dropped_cols.remove(LABEL_ID_COLUMN_NAME)

num_dropped = len(dropped_cols)

if num_dropped == 0:
    print("âœ¨ å®Œç¾ï¼æ²¡æœ‰ä¸¢å¤±ä»»ä½•åŸå§‹ç‰¹å¾åˆ—ã€‚")
else:
    print(f"âš ï¸ è­¦å‘Šï¼šæ€»å…±æœ‰ {num_dropped} ä¸ªåŸå§‹ç‰¹å¾åˆ—åœ¨å¤„ç†ä¸­æ¶ˆå¤±äº†ï¼")
    print("å¯èƒ½æ˜¯è¯»å–æ—¶è¢«è§£æé”™è¯¯ï¼Œæˆ–è€…åˆ—ååŒ…å«ç‰¹æ®Šå­—ç¬¦ã€‚")
    print("\nğŸ‘‡ ä¸¢å¤±åˆ—çš„ç¤ºä¾‹ (å‰20ä¸ª):")
    
    # è½¬æ¢æˆåˆ—è¡¨å¹¶æ’åºï¼Œæ–¹ä¾¿æŸ¥çœ‹
    dropped_list = sorted(list(dropped_cols))
    for col in dropped_list[:20]:
        print(f"   - {col}")
        
    if num_dropped > 20:
        print(f"   ... (ä»¥åŠå…¶ä»– {num_dropped - 20} ä¸ª)")

# =======================================================

# ä¿å­˜
df_final.to_csv(OUTPUT_FILE_PATH, index=False)
print(f"\næ–‡ä»¶å·²ä¿å­˜: {OUTPUT_FILE_PATH}")



# import pandas as pd
# import os
# import sys

# # ================= 1. æ–‡ä»¶è·¯å¾„é…ç½® =================
# # å®æ³¢æ•°æ®
# FILE_NINGBO = r'/data/qh_20T_share_file/lct/CT67/ningbo_ovarian_with_label.csv'

# # é™„ä¸€æ•°æ®
# FILE_FUYI = r'/data/qh_20T_share_file/lct/CT67/fuyi_ovarian_with_label.csv'

# # è¾“å‡ºåˆå¹¶åçš„æ–‡ä»¶
# FILE_OUTPUT = r'/data/qh_20T_share_file/lct/CT67/ovarian_All_Centers_with_label.csv'

# # ================= 2. æ‰§è¡Œé€»è¾‘ =================
# print("--- æ­£åœ¨åŠ è½½ä¸¤ä¸ªæ•°æ®é›† ---")

# if not os.path.exists(FILE_NINGBO) or not os.path.exists(FILE_FUYI):
#     print("!!! é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
#     sys.exit(1)

# # è¯»å–æ•°æ®
# df_ningbo = pd.read_csv(FILE_NINGBO)
# df_fuyi = pd.read_csv(FILE_FUYI)

# print(f"åŸå§‹å®æ³¢æ•°æ®: {df_ningbo.shape}")
# print(f"åŸå§‹é™„ä¸€æ•°æ®: {df_fuyi.shape}")

# # ==========================================
# # æ ¸å¿ƒä¿®æ”¹åŒºåŸŸï¼šæ ‡ç­¾æ¸…æ´—ä¸æ˜ å°„
# # ==========================================

# # 1. [é™„ä¸€] ç»Ÿä¸€åˆ—å (label -> type)
# if 'label' in df_fuyi.columns and 'type' not in df_fuyi.columns:
#     print("[å¤„ç†] é™„ä¸€æ•°æ®ï¼šå°† 'label' é‡å‘½åä¸º 'type'")
#     df_fuyi.rename(columns={'label': 'type'}, inplace=True)

# # 2. æ£€æŸ¥ä¸¤ä¸ªè¡¨æ˜¯å¦éƒ½æœ‰ type åˆ—
# if 'type' not in df_ningbo.columns or 'type' not in df_fuyi.columns:
#     print("!!! è‡´å‘½é”™è¯¯: ç¼ºå°‘ 'type' (æˆ– label) æ ‡ç­¾åˆ—ï¼Œæ— æ³•ç»§ç»­ã€‚")
#     sys.exit(1)

# # 3. [é€šç”¨] å»é™¤æ²¡æœ‰æ ‡ç­¾çš„æ ·æœ¬ (Drop NaN)
# print("[å¤„ç†] æ­£åœ¨å»é™¤æ— æ ‡ç­¾çš„æ ·æœ¬...")
# before_n = len(df_ningbo)
# df_ningbo.dropna(subset=['type'], inplace=True)
# print(f"   - å®æ³¢: {before_n} -> {len(df_ningbo)} (å‰”é™¤ {before_n - len(df_ningbo)})")

# before_f = len(df_fuyi)
# df_fuyi.dropna(subset=['type'], inplace=True)
# print(f"   - é™„ä¸€: {before_f} -> {len(df_fuyi)} (å‰”é™¤ {before_f - len(df_fuyi)})")

# # 4. [é€šç”¨] å¼ºåˆ¶è½¬æ¢ä¸ºå­—ç¬¦ä¸² (Character)
# #    é˜²æ­¢ pandas è‡ªåŠ¨è¯†åˆ«ä¸ºæ•°å€¼ï¼Œæ»¡è¶³"typeåº”è¯¥æ˜¯å­—ç¬¦"çš„éœ€æ±‚
# #    æ³¨æ„ï¼šå…ˆè½¬ä¸ºintå†è½¬stræ˜¯ä¸ºäº†é˜²æ­¢å‡ºç° "1.0" è¿™æ ·çš„å­—ç¬¦ä¸²
# try:
#     df_ningbo['type'] = df_ningbo['type'].astype(float).astype(int).astype(str)
# except:
#     df_ningbo['type'] = df_ningbo['type'].astype(str)

# try:
#     df_fuyi['type'] = df_fuyi['type'].astype(float).astype(int).astype(str)
# except:
#     df_fuyi['type'] = df_fuyi['type'].astype(str)

# print(f"[æ£€æŸ¥] å®æ³¢ type åˆ—ç±»å‹: {df_ningbo['type'].dtype}")
# print(f"[æ£€æŸ¥] é™„ä¸€ type åˆ—ç±»å‹: {df_fuyi['type'].dtype}")

# # 5. [å®æ³¢ç‰¹æœ‰] æ ‡ç­¾æ•°å€¼ä¿®æ”¹ (0->1, 1->2)
# #    å› ä¸ºä¸Šé¢å·²ç»å¼ºåˆ¶è½¬ä¸ºå­—ç¬¦ä¸²äº†ï¼Œè¿™é‡Œæ›¿æ¢å­—ç¬¦ä¸² '0' å’Œ '1'
# print("[å¤„ç†] æ­£åœ¨ä¿®æ”¹å®æ³¢æ ‡ç­¾: 0->1, 1->2")
# mapping = {'0': '1', '1': '2'}
# # æ£€æŸ¥ä¸€ä¸‹æ›¿æ¢å‰çš„å€¼åˆ†å¸ƒ
# print(f"   - æ›¿æ¢å‰åˆ†å¸ƒ: {df_ningbo['type'].value_counts().to_dict()}")

# # æ‰§è¡Œæ›¿æ¢
# df_ningbo['type'] = df_ningbo['type'].replace(mapping)

# # æ£€æŸ¥æ›¿æ¢åçš„å€¼åˆ†å¸ƒ
# print(f"   - æ›¿æ¢ååˆ†å¸ƒ: {df_ningbo['type'].value_counts().to_dict()}")

# # ==========================================
# # åç»­åˆå¹¶é€»è¾‘ (ä¿æŒåŸæœ‰å¯¹é½é€»è¾‘)
# # ==========================================

# # --- æ£€æŸ¥åˆ—å·®å¼‚ ---
# cols_ningbo = set(df_ningbo.columns)
# cols_fuyi = set(df_fuyi.columns)
# common_cols = cols_ningbo.intersection(cols_fuyi)

# print(f"\n--- åˆ—ååŒ¹é…æ£€æŸ¥ ---")
# print(f"1. å…¬å…±ç‰¹å¾åˆ—æ•°: {len(common_cols)} (è¿™äº›å°†è¢«åˆå¹¶)")

# if 'Center' not in common_cols:
#     print("!!! è­¦å‘Š: ä¸¤ä¸ªè¡¨æ²¡æœ‰å…±åŒçš„ 'Center' åˆ—ï¼Œå»ºè®®åˆå¹¶åæ£€æŸ¥æ¥æºã€‚")

# # --- åˆå¹¶ ---
# print("\n--- æ­£åœ¨åˆå¹¶ ---")
# # join='inner' åªä¿ç•™å…¬å…±åˆ—
# df_merged = pd.concat([df_ningbo, df_fuyi], axis=0, join='inner', ignore_index=True)

# # è°ƒæ•´åˆ—é¡ºåº
# first_cols = ['ID', 'Center', 'type']
# first_cols = [c for c in first_cols if c in df_merged.columns]
# other_cols = [c for c in df_merged.columns if c not in first_cols]
# df_final = df_merged[first_cols + other_cols]

# # æœ€ç»ˆä¿å­˜
# df_final.to_csv(FILE_OUTPUT, index=False)

# print(f"{'='*40}")
# print(f"åˆå¹¶å®Œæˆï¼")
# print(f"æœ€ç»ˆæ–‡ä»¶: {FILE_OUTPUT}")
# print(f"æœ€ç»ˆå½¢çŠ¶: {df_final.shape}")
# if 'Center' in df_final.columns:
#     print(f"åŒ…å«ä¸­å¿ƒåŠæ ·æœ¬é‡: \n{df_final['Center'].value_counts()}")
# print(f"æ ‡ç­¾åˆ†å¸ƒ (type): \n{df_final['type'].value_counts()}")
# print(f"{'='*40}")